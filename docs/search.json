[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "tidymodels is an R framework designed for machine learning and statistical modeling. Built on the principles of the tidyverse, tidymodels provides a consistent and modular approach to tasks like data preprocessing, model training, evaluation, and validation. By leveraging the strengths of packages such as recipes, parsnip, and yardstick, tidymodels streamlines the modeling workflow, making it easier to experiment with different models while maintaining reproducibility and interpretability.\nloading packages for analysis\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n\n\n✔ broom        1.0.7     ✔ recipes      1.2.1\n✔ dials        1.4.0     ✔ rsample      1.2.1\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.2     ✔ tidyr        1.3.1\n✔ infer        1.0.7     ✔ tune         1.3.0\n✔ modeldata    1.4.0     ✔ workflows    1.2.0\n✔ parsnip      1.3.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.4     ✔ yardstick    1.3.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(visdat)\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(parsnip)\nlibrary(recipes)\nlibrary(yardstick)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.4     ✔ stringr   1.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(ggthemes)\nWhy the hype about stream data? This is a large dataset that’s helped to enhance deep learning and model tuning while being a tool for understanding model behavior. It facilitates large-scale model comparisons and allows for hybrid models that combine physics based models with machine learning.\nWhat’s in the data? Each record in the CAMELS dataset represents a unique river basin, identified by an outlet USGS NWIS gauge_id. The dataset contains a mix of continuous and categorical variables, including meteorological, catchment, and streamflow summaries.\nThe data we are going to downloaded are the basin level summaries. For example, if we looked at row 1 of the data (Gage: 01013500) all of the values are the areal average for the drainage basin, while the flow metrics are associated with the outlet gage.\nThe CAMELS dataset is hosted by NCAR and can be accessed here under the “Individual Files” section. The root URL for all data seen on the “Individual Files” page is:\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\nNear the bottom of that page, there are many .txt files that contain the data we want. Some hold climate data for each basin, some hold geology data, some hold soil data, etc. There is also a PDF with descriptions of the columns in each file. We are going to download all of the .txt files and the PDF."
  },
  {
    "objectID": "lab6.html#getting-the-documentation-pdf",
    "href": "lab6.html#getting-the-documentation-pdf",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Getting the documentation PDF",
    "text": "Getting the documentation PDF\n\nfile &lt;- 'https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf'\n\ndownload.file(file, \"C:/Users/Joshua Puyear/Documents/csu-undergrad/ess-330-joshp-2025/github/ess-330-labs/06-hydrology-ml/docs/camels_attributes.pdf\", mode = \"wb\")"
  },
  {
    "objectID": "lab6.html#getting-basin-characteristics",
    "href": "lab6.html#getting-basin-characteristics",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Getting Basin Characteristics",
    "text": "Getting Basin Characteristics\nThe glue package provides an efficient way to interpolate and manipulate strings. It is particularly useful for dynamically constructing text, formatting outputs, and embedding R expressions within strings.\nNow we want to download the .txt files that store the actual data documented in the PDF. Doing this file by file (like we did with the PDF) is possible, but lets look at a better/easier way…\n\na. Lets create a vector storing the data types/file names we want to download:\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n\n\nb. Using glue, we can construct the needed URLs and file names for the data we want to download:\n\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\n\n\nc. Now we can download the data: walk2 comes from the purrr package and is used to apply a function to multiple arguments in parallel (much like map2 works over paired lists). Here, we are asking walk2 to pass the first element of remote_files and the first element of local_files to the download.file function to download the data, and setting quiet = TRUE to suppress output. The process is then iterated for the second element of each vector, and so on.\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n\n\nd. Once downloaded, the data can be read into R using readr::read_delim(), again instead of applying this to each file individually, we can use map to apply the function to each element of the local_files list.\n\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\n\n\ne. This gives us a list of data.frames, one for each file that we want to merge into a single table. So far in class we have focused on *_join functions to merge data based on a primary and foreign key relationship.\nIn this current list, we have &gt;2 tables, but, have a shared column called gauge_id that we can use to merge the data. However, since we have more then a left and right hand table, we need a more robust tool. We will use the powerjoin package to merge the data into a single data frame. powerjoin is a flexible package for joining lists of data.frames. It provides a wide range of join types, including inner, left, right, full, semi, anti, and cross joins making it a versatile tool for data manipulation and analysis, and one that should feel familiar to users of dplyr.\nIn this case, we are join to merge every data.frame in the list (n = 6) by the shared gauge_id column. Since we want to keep all data, we want a full join.\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "lab6.html#exploratory-data-analysis",
    "href": "lab6.html#exploratory-data-analysis",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nFirst, lets make a map of the sites. Use the borders() ggplot function to add state boundaries to the map and initially color the points by the mean flow (q_mean) at each site.\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map() +\n  labs(\n    title = \"Mean Streamflow Across the US\",\n    color = \"Mean Streamflow q\"\n  )\n\n\n\n\n\n\n\n\n\nQ1 Answers\nAt this point, all of the data and the PDF are downloaded into my directory\nzero_q_freq represents frequency of days with Q = 0 mm/day, and is listed as a percentage."
  },
  {
    "objectID": "lab6.html#model-preparation",
    "href": "lab6.html#model-preparation",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Preparation",
    "text": "Model Preparation\nAs an initial analysis, lets look at the relationship between aridity, rainfall and mean flow. First, lets make sure there is not significant correlation between these variables. Here, we make sure to drop NAs and only view the 3 columns of interest.\n\n#making a correlation matrix\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\nEven though aridity has a strong inverse correlation with streamflow and prcip has a strong positive correlation with streamflow, we’re still using these variables to predict the model"
  },
  {
    "objectID": "lab6.html#visual-eda",
    "href": "lab6.html#visual-eda",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Visual EDA",
    "text": "Visual EDA\n\na. Lets start by looking that the 3 dimensions (variables) of this data. We’ll start with a XY plot of aridity and rainfall. We are going to use the scale_color_viridis_c() function to color the points by the q_mean column. This scale functions maps the color of the points to the values in the q_mean column along the viridis continuous (c) palette. Because a scale_color_* function is applied, it maps to the known color aesthetic in the plot.\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nBy showing an x-y axis and color, it is possible for two variables to predict a third. These three dimensions can explain what’s happening with streamflow. At this point, we’re just showing what’s happening in the available data.\nSo it looks like there is a relationship between rainfall, aridity, and rainfall but it looks like an exponential decay function and is certainly not linear.\nTo test a transformation, we can log transform the x and y axes using the scale_x_log10() and scale_y_log10() functions:\n\n#when you plot the logged version of this, the relationship becomes linear because of how logs turn multiplicative properties into additive ones.\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nGreat! We can see a log-log relationship between aridity and rainfall provides a more linear relationship. This is a common relationship in hydrology and is often used to estimate rainfall in ungauged basins. However, once the data are transformed, the lack of spread in the streamflow data is quite evident with high mean flow values being compressed to the low end of aridity/high end of rainfall.\nTo address this, we can visualize how a log transform may benifit the q_mean data as well. Since the data is represented by color, rather then an axis, we can use the trans (transform) argument in the scale_color_viridis_c() function to log transform the color scale.\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nExcellent! Treating these three right skewed variables as log transformed, we can see a more evenly spread relationship between aridity, rainfall, and mean flow. This is a good sign for building a model to predict mean flow using aridity and rainfall."
  },
  {
    "objectID": "lab6.html#naive-base-lm-approach",
    "href": "lab6.html#naive-base-lm-approach",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Naive base lm approach",
    "text": "Naive base lm approach\nOk, to start, lets do what we are comfortable with … fitting a linear model to the data. First, we use prep and bake on the training data to apply the recipe. Then, we fit a linear model to the data.\n\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\n# Interaction with lm\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Sanity Interaction term from recipe ... these should be equal!!\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "lab6.html#where-things-get-a-little-messy",
    "href": "lab6.html#where-things-get-a-little-messy",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Where things get a little messy…",
    "text": "Where things get a little messy…\nOk so now we have our trained model lm_base and want to validate it on the test data.\nRemember a models ability to predict on new data is the most important part of the modeling process. It really doesnt matter how well it does on data it has already seen!\nWe have to be careful about how we do this with the base R approach:\nDon’t use augment directly on the test data before preprocessing has been applied to the data, otherwise the values it will add to the data will be incorrect Don’t use predict on the test data before preprocessing steps have been applied to the test data"
  },
  {
    "objectID": "lab6.html#correct-version-prep---bake---predict",
    "href": "lab6.html#correct-version-prep---bake---predict",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Correct version: prep -> bake -> predict",
    "text": "Correct version: prep -&gt; bake -&gt; predict\nTo correctly evaluate the model on the test data, we need to apply the same preprocessing steps to the test data that we applied to the training data. We can do this using the prep and bake functions with the recipe object. This ensures the test data is transformed in the same way as the training data before making predictions.\n\ntest_data &lt;- bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)"
  },
  {
    "objectID": "lab6.html#model-evaluation-statistical-and-visual",
    "href": "lab6.html#model-evaluation-statistical-and-visual",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Evaluation: statistical and visual",
    "text": "Model Evaluation: statistical and visual\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")"
  },
  {
    "objectID": "lab6.html#using-a-workflow-instead",
    "href": "lab6.html#using-a-workflow-instead",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Using a workflow instead",
    "text": "Using a workflow instead\ntidymodels provides a framework for building and evaluating models using a consistent and modular workflow. The workflows package allows you to define a series of modeling steps, including data preprocessing, model fitting, and model fitting, in a single object. This makes it easier to experiment with different models, compare performance, and ensure reproducibility.\nworkflows are built from a model, a preprocessor, and a execution. Here, we are going to use the linear_reg function to define a linear regression model, set the engine to lm, and the mode to regression. We then add our recipe to the workflow, fit the model to the training data, and extract the model coefficients.\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train)\n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\nLets ensure we replicated the results from the lm_base model. How do they look to you?\n\n# From the base implementation\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01"
  },
  {
    "objectID": "lab6.html#making-predictions",
    "href": "lab6.html#making-predictions",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Making Predictions",
    "text": "Making Predictions\nNow that lm_wf is a workflow, data is not embedded in the model, we can use augment with the new_data argument to make predictions on the test data.\n\n#\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61"
  },
  {
    "objectID": "lab6.html#model-evaluation-statistical-and-visual-1",
    "href": "lab6.html#model-evaluation-statistical-and-visual-1",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Evaluation: Statistical and Visual",
    "text": "Model Evaluation: Statistical and Visual\nAs with EDA, applying for graphical and statistical evaluation of the model is a key Here, we use the metrics function to extract the default metrics (rmse, rsq, mae) between the observed and predicted mean streamflow values.\nWe then create a scatter plot of the observed vs predicted values, colored by aridity, to visualize the model performance.\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()"
  },
  {
    "objectID": "lab6.html#switch-it-up",
    "href": "lab6.html#switch-it-up",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Switch it up!",
    "text": "Switch it up!\nThe real power of this approach is that we can easily switch out the models/recipes and see how it performs. Here, we are going to instead use a random forest model to predict mean streamflow. We define a random forest model using the rand_forest function, set the engine to ranger, and the mode to regression. We then add the recipe, fit the model, and evaluate the skill.\n\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train)"
  },
  {
    "objectID": "lab6.html#predictions",
    "href": "lab6.html#predictions",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Predictions",
    "text": "Predictions\nMake predictions on the test data using the augment function and the new_data argument.\n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60"
  },
  {
    "objectID": "lab6.html#model-evaluation-statistical-and-visual-2",
    "href": "lab6.html#model-evaluation-statistical-and-visual-2",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Model Evaluation: statistical and visual",
    "text": "Model Evaluation: statistical and visual\nEvaluate the model using the metrics function and create a scatter plot of the observed vs predicted values, colored by aridity.\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.596\n2 rsq     standard       0.733\n3 mae     standard       0.370\n\n\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\nAwesome! We just set up a completely new model and were able to utilize all of the things we had done for the linear model. This is the power of the tidymodels framework!\nThat said, we still can reduce some to the repetition. Further, we are not really able to compare these models to one another as they"
  },
  {
    "objectID": "lab6.html#a-workflowset-approach",
    "href": "lab6.html#a-workflowset-approach",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "A workflowset approach",
    "text": "A workflowset approach\nworkflow_set is a powerful tool for comparing multiple models on the same data. It allows you to define a set of workflows, fit them to the same data, and evaluate their performance using a common metric. Here, we are going to create a workflow_set object with the linear regression and random forest models, fit them to the training data, and compare their performance using the autoplot and rank_results functions.\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.565  0.0243    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.770  0.0255    10 recipe       rand…     1\n3 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     2\n\n\nOverall it seems the random forest model is outperforming the linear model. This is not surprising given the non-linear relationship between the predictors and the outcome :)"
  },
  {
    "objectID": "lab6.html#data-splitting-15",
    "href": "lab6.html#data-splitting-15",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Data Splitting (15)",
    "text": "Data Splitting (15)\n\nSet a seed for reproducible\n\nset.seed(295)\n\n\n\nCreate an initial split with 75% used for training and 25% for testing\n\ncamels_split2 &lt;- initial_split(camels, prop = 0.75)\n\n\n\nExtract your training and testing sets. Build a 10-fold CV dataset as well\n\ncamels_train2 &lt;- training(camels_split2)\ncamels_test2  &lt;- testing(camels_split2)\n\n#ten-fold cross-validation dataset\ncamels_cv2 &lt;- vfold_cv(camels_train2, v = 10)"
  },
  {
    "objectID": "lab6.html#recipe-15",
    "href": "lab6.html#recipe-15",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Recipe (15)",
    "text": "Recipe (15)\n\nDefine a formula you want to use to predict logQmean\n\n\nBuild a recipe that you feel handles the predictors chosen well\n\n#here i was wondering if it would be worthwhile to try to plot all of these variables, or if it's better to make them a part of the model and just see if it works.\n\nrec2 &lt;-  recipe(logQmean ~ aridity + p_mean + high_prec_freq + low_prec_freq + high_prec_dur + lai_max + water_frac + slope_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  #step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\nstep_interact(terms = ~ aridity:p_mean + aridity:lai_max + p_mean:low_prec_freq + high_prec_freq:low_prec_freq + low_prec_freq:aridity) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n\n\n\nDescribe in words why you are choosing the formula you are. Consult the downloaded PDF for the data to help you make this decision.\n\nI chose high_prec_freq (high precipitation frequency) because it’s distant enough from p_mean to be a different concept.\nlow_prec_freq will reflect droughts frequency, which will be directly related to average streamflow for at least part of the season\nhigh_prec_dur will greatly weigh into average sreamflow because it describes how often events 9x the median flow occur.\nlai_max is an ecological predictor that assumes in areas with broad leaves there is more available moisture in the environment, which should increase streamflow\nfraction of the top 1.5m of soil marked as water- this should be positively correlated with streamflow if there is an overall higher water table *slope_mean should contribute to streamflow because a higher slope will increase velocity\n\nSince there are so many terms, I am not going to try to visualize all of them. I will run the model and see if it works. I am curious about which terms interact though, so I think I’ll make a correlation table.\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean, high_prec_freq, low_prec_freq, high_prec_dur, lai_max, soil_conductivity, water_frac) |&gt; \n  drop_na() |&gt; \n  cor()\n\n                      aridity      p_mean      q_mean high_prec_freq\naridity            1.00000000 -0.75500903 -0.58177710     0.50924192\np_mean            -0.75500903  1.00000000  0.88657569    -0.60030682\nq_mean            -0.58177710  0.88657569  1.00000000    -0.66875889\nhigh_prec_freq     0.50924192 -0.60030682 -0.66875889     1.00000000\nlow_prec_freq      0.74178481 -0.72523441 -0.71457114     0.87176299\nhigh_prec_dur      0.41619443 -0.10924664  0.09566366     0.16493933\nlai_max           -0.70476393  0.58782662  0.37907296    -0.36234645\nsoil_conductivity -0.03011819  0.08253143  0.03534482    -0.10870127\nwater_frac         0.03283288 -0.06632260 -0.03646015    -0.03122678\n                  low_prec_freq high_prec_dur     lai_max soil_conductivity\naridity              0.74178481   0.416194434 -0.70476393       -0.03011819\np_mean              -0.72523441  -0.109246644  0.58782662        0.08253143\nq_mean              -0.71457114   0.095663663  0.37907296        0.03534482\nhigh_prec_freq       0.87176299   0.164939334 -0.36234645       -0.10870127\nlow_prec_freq        1.00000000   0.349279796 -0.59053772       -0.07317975\nhigh_prec_dur        0.34927980   1.000000000 -0.47842289        0.05751086\nlai_max             -0.59053772  -0.478422889  1.00000000        0.02222807\nsoil_conductivity   -0.07317975   0.057510862  0.02222807        1.00000000\nwater_frac          -0.01544770  -0.006140105 -0.04983244        0.07338496\n                    water_frac\naridity            0.032832877\np_mean            -0.066322596\nq_mean            -0.036460152\nhigh_prec_freq    -0.031226777\nlow_prec_freq     -0.015447702\nhigh_prec_dur     -0.006140105\nlai_max           -0.049832438\nsoil_conductivity  0.073384956\nwater_frac         1.000000000\n\n\n\n\nDefine 3 models (25)\n\n#random forest with ranger and regression\nlibrary(baguette)\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\n#I will be using the neural network model and xgboost\n\n\n\nworkflow set ()\n\nwf2 &lt;- workflow_set(list(rec2), list(lm_model, rf_model, nnet_model, xgboost_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv2) \n\nautoplot(wf2)\n\n\n\n\n\n\n\nrank_results(wf2, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_rand_fore… Prepro… rmse    0.379  0.0369    10 recipe       rand…     1\n2 recipe_rand_fore… Prepro… rsq     0.896  0.0170    10 recipe       rand…     1\n3 recipe_boost_tree Prepro… rmse    0.369  0.0382    10 recipe       boos…     2\n4 recipe_boost_tree Prepro… rsq     0.891  0.0244    10 recipe       boos…     2\n5 recipe_linear_reg Prepro… rmse    0.459  0.0385    10 recipe       line…     3\n6 recipe_linear_reg Prepro… rsq     0.852  0.0187    10 recipe       line…     3\n7 recipe_bag_mlp    Prepro… rmse    0.741  0.0627    10 recipe       bag_…     4\n8 recipe_bag_mlp    Prepro… rsq     0.804  0.0360    10 recipe       bag_…     4\n\n\nThe random forest did the best with an r squared of.89, followed by rand_forest at .88, according to the autoplot. I think these tree-based models did better because there wasn’t a lot of data to go by, allowing for more accurate modeling with decision trees. Boost_tree builds sequentially, while random forests build parallel. The sequential building was slightly better."
  },
  {
    "objectID": "lab6.html#extact-and-evaluate",
    "href": "lab6.html#extact-and-evaluate",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Extact and Evaluate",
    "text": "Extact and Evaluate\nNow that you found your favorite model, lets see how it does on the test data!\n\nBuild a workflow (not workflow set) with your favorite model, recipe, and training data\n\n\nUse fit to fit all training data to the model\n\nrandflow &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec2) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train2)\n\n\n\nUse augment to make predictions on the test data\n\nrandflow_data &lt;- augment(randflow, new_data = camels_test2)\ndim(randflow_data)\n\n[1] 168  60\n\n\n\n\nCreate a plot of the observed vs predicted values with clear title, axis labels, and a compelling color scale\n\nggplot(randflow_data, aes(x = logQmean, y = .pred)) +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw() +\n  labs(\n    y = \"Predictor variables\",\n    x = \"Streamflow\",\n    title = \"Boosted Forest Prediction model\"\n  )\n\n\n\n\n\n\n\n\n\n\nDescribe what you think of the results!\nThe line of best fit is much more accurate at higher log streamflow, but at lower streamflow the values are more spread out. It appears as though since the R^2 converges, there might be more interacting variables I wasn’t catching at first."
  }
]